── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.0     ✔ purrr   0.3.4
✔ tibble  3.0.1     ✔ dplyr   0.8.5
✔ tidyr   1.0.2     ✔ stringr 1.4.0
✔ readr   1.3.1     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Loading required package: StanHeaders
rstan (Version 2.19.3, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

This is loo version 2.2.0
- Online documentation and vignettes at mc-stan.org/loo
- As of v2.0.0 loo defaults to 1 core but we recommend using as many as possible. Use the 'cores' argument or set options(mc.cores = NUM_CORES) for an entire session. 

Attaching package: ‘loo’

The following object is masked from ‘package:rstan’:

    loo

[1] "Model: GL_LMA"
[1] "Model dir: ./model/GL_LMA.stan"
[1] "Data: GL"
[1] "n_iter = 4000"
[1] "n_warm = 3000"
[1] "n_thin = 1"
[1] "n_chains = 4"
OBS data
Parsed with column specification:
cols(
  sp = col_character(),
  DE = col_character(),
  GF = col_character(),
  LL = col_double(),
  LMA = col_double(),
  Aarea = col_double(),
  Rarea = col_double()
)

SAMPLING FOR MODEL 'GL_LMA' NOW (CHAIN 1).

SAMPLING FOR MODEL 'GL_LMA' NOW (CHAIN 2).

SAMPLING FOR MODEL 'GL_LMA' NOW (CHAIN 3).

SAMPLING FOR MODEL 'GL_LMA' NOW (CHAIN 4).
Chain 1: 
Chain 1: Gradient evaluation took 0.000288 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 2.88 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 2: 
Chain 2: Gradient evaluation took 0.000286 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 2.86 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 2: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 3: 
Chain 3: Gradient evaluation took 0.000255 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 2.55 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 4: 
Chain 4: Gradient evaluation took 0.000253 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 2.53 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 3: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 4: Iteration:    1 / 4000 [  0%]  (Warmup)
Chain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)
Chain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)
Chain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)
Chain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)
Chain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)
Chain 4: Iteration: 2400 / 4000 [ 60%]  (Warmup)
Chain 3: Iteration: 2400 / 4000 [ 60%]  (Warmup)
Chain 1: Iteration: 2400 / 4000 [ 60%]  (Warmup)
Chain 2: Iteration: 2400 / 4000 [ 60%]  (Warmup)
Chain 4: Iteration: 2800 / 4000 [ 70%]  (Warmup)
Chain 3: Iteration: 2800 / 4000 [ 70%]  (Warmup)
Chain 3: Iteration: 3001 / 4000 [ 75%]  (Sampling)
Chain 4: Iteration: 3001 / 4000 [ 75%]  (Sampling)
Chain 2: Iteration: 2800 / 4000 [ 70%]  (Warmup)
Chain 1: Iteration: 2800 / 4000 [ 70%]  (Warmup)
Chain 2: Iteration: 3001 / 4000 [ 75%]  (Sampling)
Chain 3: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 1: Iteration: 3001 / 4000 [ 75%]  (Sampling)
Chain 4: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 2: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 3: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 3: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 157.963 seconds (Warm-up)
Chain 3:                27.4427 seconds (Sampling)
Chain 3:                185.405 seconds (Total)
Chain 3: 
Chain 1: Iteration: 3400 / 4000 [ 85%]  (Sampling)
Chain 4: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 2: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 4: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 161.4 seconds (Warm-up)
Chain 4:                33.269 seconds (Sampling)
Chain 4:                194.669 seconds (Total)
Chain 4: 
Chain 2: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 168.042 seconds (Warm-up)
Chain 2:                28.1636 seconds (Sampling)
Chain 2:                196.205 seconds (Total)
Chain 2: 
Chain 1: Iteration: 3800 / 4000 [ 95%]  (Sampling)
Chain 1: Iteration: 4000 / 4000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 172.576 seconds (Warm-up)
Chain 1:                38.3817 seconds (Sampling)
Chain 1:                210.958 seconds (Total)
Chain 1: 
Warning messages:
1: The largest R-hat is NA, indicating chains have not mixed.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#r-hat 
2: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#bulk-ess 
3: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html#tail-ess 
Saved `./rda/GL_LMA_obs.rda`!!
