---
title: "Katabuchi et al., Decomposing leaf mass into metabolic and structural components explains divergent patterns of trait variation within and among plant species"
fontsize: 12pt
geometry: margin=1in
link-citations: yes
csl: apa-6th-edition.csl
bibliography: [LMA.bib]
# crossref:
#   eq-prefix: Eq.
#   fig-title: Fig. S
#   fig-prefix: Fig. S
format:
  html:
    theme: spacelab #readable #sandstone #spacelab #flatly
    toc: true
    toc-depth: 2
    toc-title: Contents
    self-contained: true
    smooth-scroll: true
    highlight-style: github
  docx:
    toc: true
    number-sections: false
    highlight-style: github
    html-math-method: katex
    reference-doc: my_template.docx
  pdf:
    toc: true
    keep-tex: true
    latex-clean: true
    pdf-engine: pdflatex
    include-in-header:
      text: |
        \usepackage{xr}
        \externaldocument{LMAms_main}
        \usepackage{float}
        \usepackage{booktabs}
        \usepackage{colortbl}
        \usepackage{fancyhdr}
        \pagestyle{fancy}
        \usepackage[default]{sourcesanspro}
        \usepackage{sourcecodepro}
        \usepackage{fvextra}
        \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
        \fancyhead[RE,RO]{Katabuchi \textit{et al}.  Appendix}
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r caching, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(here)
here::i_am("ms/LMAms_SI.qmd")
para <- yaml::yaml.load_file(here("yml/para.yml"))
source(here("R/render.R"))
```

```{r, include=FALSE}
# Make sure the order is correct
fig("hypo")
fig("gl_point")
fig("pa_point")
fig("ll_point")
fig("vpart")
fig("box_de")
fig("box_pa")
fig("mass_prop")
fig("pa_npc")
```

\newpage

# Appendix S1: Prior information

The logarithms of *A*~area~, *R*~area~, and LL for leaf sample *i* were assumed to have a multivariate normal distribution as following:

$$
\begin{aligned}
\left(
\begin{array}{ccc}
\mathrm{ln}(A_{\mathrm{area} \, i})\\
\mathrm{ln}(R_{\mathrm{area} \, i}) \\
\mathrm{ln}(\mathrm{LL}_i)
\end{array}
\right)
\sim \mathrm{MVN}
\left(
\begin{array}{rrr}
\mathrm{E}[A_{\mathrm{area} \, i}] & \\
\mathrm{E}[R_{\mathrm{area} \, i}] &, \boldsymbol{\Sigma}\\
\mathrm{E}[\mathrm{LL}_i] &
\end{array}
\right) \qquad(\mathrm{S}1)
\end{aligned}
$$

where E[$\cdot$] indicates expected value; $\boldsymbol{\Sigma}$ indicates a covariance matrix.
Expected values are based on Eqs. 2-4 in the main text.

We used non-informative or weakly informative prior distributions [@Lemoine2019].
The covariance mkatrix in Eq. S1 was decomposed as ${\mathbf \Sigma} = {\mathrm diag}({\mathbf \sigma}){\mathbf \Omega}{\mathrm diag}({\mathbf \sigma}) = {\mathrm diag}({\mathbf \sigma}){\mathbf L}{\mathbf L}\prime {\mathrm diag}({\mathbf \sigma})$ using a Cholesky decomposition, where ${\mathbf \sigma}$ is a vector of $\sigma_{1}$, $\sigma_{2}$, and $\sigma_{3}$;  ${\mathbf \Omega}$ is a correlation matrix of $\rho_{12}$, $\rho_{13}$, and $\rho_{23}$; and **L** is a lower triangular matrix.
Instead of assigning prior distributions on directly, priors were assigned on and **L** to avoid a strong dependence between and [@Lewandowski2009; @Alvarez2014].
A prior for **L** was specified as a so-called LKJ distribution with shape parameter 2 [@Lewandowski2009], which is weakly informative for the correlation matrix.
A prior for ${\mathrm diag}({\mathbf \sigma})$ was specified as a Half-Cauchy distribution with location 0 and scale 2.5, which is weakly informative and allows for occasional large coefficients while still performing a reasonable amount of shrinkage for coefficients near zero [@Gelman2008].

A prior for $\mathbf{\sigma}$ was specified as a Half-Cauchy distribution with location 0 and scale 5, which is weakly informative and allows for occasional large coefficients while still performing a reasonable amount of shrinkage for coefficients near zero [@Gelman2008].

Priors for $\alpha_{0,m,s}$, $\beta_{0,m,s}$, and $\gamma_{0,m,s}$ in Eqs. 4-6 were weakly informative and specified as normal distributions with mean 0 and standard deviation 5.
Priors for *f~i~* in Eqs. 1-4 were non-informative and specified as uniform distributions with range (0, 1).

\newpage

# Appendix S2: Randomization (including Table AS1 and Figure AS1)

We generated 10 randomized datasets for each of the GLOPNET and the Panama datasets by shuffling each trait value across leaf samples, and fit the best models (Appendix S1) to the randomized data.

## Table AS1

- No_large_Rhat: The number of parameters (including transformed parameters) that shows Rhat (Gelman-Rubin statistic) greater than 1.1.

- No_divergence: The number of iterations that shows divergent transitions.

```{r randtab, echo=FALSE, eval=TRUE}
d <- read_csv(here("data/sim_summary_diagnostics.csv")) #|>
  # dplyr::select(Data = data, Simulation_ID = sim_id, No_large_Rhat = rhat, No_divergence = div)

if ("html" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  # knitr::kable(d, format = "pipe", escape = FALSE) |>
  kable(d) |>
    #kable_styling()
    kable_classic(full_width = FALSE)
} else if ("docx" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  d |>
    kable(format = "pipe", escape = FALSE) |>
    kable_classic(full_width = FALSE)
} else if ("latex" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  d |>
    kable(format = "pipe", escape = FALSE) |>
    kable_classic(full_width = FALSE)
}
```

Most of the model results obtained from the randomized datasets did not convergent based on the Gelman-Rubin statistic or showed divergent transitions.

\newpage

## Figure AS1

Although many parameters showed large Rhat values, which suggests that the posterior distributions were not converged well, we checked the regression coefficients for the GLOPNET dataset ($\alpha_{0, m, s}$, $\beta_{0, s}$, and $\gamma_{0, m, s}$ in Eqs. 2-4 in the main text).
There are 10 independent simulations (randomizations) in total.
Points and lines indicate posterior medians and 95% credible intervals (CIs), respectively.
Although intercepts were significant, the scaling parameters in the randomized datasets did not show any patterns.
Thus, the tests with randomized data indicate that our model is not inherently prone to overfitting or to producing patterns from noise.

![](`r here("figs/coef_sim_gl.png")`)

\newpage

## Figure AS2

We also checked the regression coefficients for the Panama dataset ($\alpha_{0, m}$, $\beta_{0, s}$, $\gamma_{0, m, s}$ and $\theta$ in Eqs. 2-4 in the main text).
Details as for Figure AS1.
The scaling parameters in the randomized datasets did not show any patterns

![](`r here("figs/coef_sim_pa.png")`)

\newpage

# Appendix S3: Simulation for mass dependency of *A*~area~

To simulate mass dependency of *A*~area~, we generated LMAm and LMAs values for leaf sample *i* using normal distributions (N) for GLPONET and sun leaves of Panama with a sample size of 100:

$$
\mathrm{ln}(\mathrm{LMAm}_{i}) \sim N(\mathrm{ln}(\mu_m), \sigma_m)
$$

$$
\mathrm{ln}(\mathrm{LMAs}_{i}) \sim N(\mathrm{ln}(\mu_s), \sigma_s)
$$

where
$\mu_m$ and $\mu_s$ are the mean of LMAm and LMAs on the log-scale, respectively, and
$\sigma_m$ and $\sigma_s$ are the standard deviation of LMAm and LMAs on the log-scale, respectively.

Because there was a weak negative correlation between LMAm and LMAs values of shade leaves in Panama, LMAm and LMAs values were generated using a multivariate normal distribution (MVN):

$$
\begin{bmatrix}
\mathrm{ln}(\mathrm{LMAm}_{i})\\
\mathrm{ln}(\mathrm{LMAs}_{i})
\end{bmatrix}
\sim \mathrm{MVN}
\left[
\begin{matrix}
\ln(\mu_{p})\\
\ln(\mu_{s})
\end{matrix}
,\mathbf{\Sigma}
\right]
$$

$$
\mathbf{\Sigma} = \
\begin{bmatrix}
\sigma_m^2 & \rho \sigma_m \sigma_s \\
\rho \sigma_m \sigma_s & \sigma_s^2 \\
\end{bmatrix}
$$

where $\Sigma$ is the covariance matrix of ln(LMAm) and ln(LMAs),
$\rho$ is the correlation coefficient between ln(LMAm) and ln(LMAs).

We used the empirical estimates for $\mu_m$, $\mu_s$, $\sigma_m$, and $\rho$ while with changing $\sigma_s$ between ln(1.01) and ln(10).
*A*~area~ was then generated based the values obtained from the above simulation:

$$
\mathrm{ln}(A_{\mathrm{area} \, i}) = \mathrm{ln}(\alpha_0) + \alpha_m\mathrm{ln}(\mathrm{LMAm}_{i}) + \alpha_s\mathrm{ln}(\mathrm{LMAs}_{i}).
$$

Parameter settings are as following,
GLOPNET:
$\mu_m$ = `r para$GL$LMAm_mu_gl`,
$\mu_s$ = `r para$GL$LMAs_mu_gl`,
$\sigma_m$ = `r para$GL$LMAm_sig_gl`,
$\alpha_m$ = `r para$GL$am`,
$\alpha_s$ = `r para$GL$as`,
sun leaves in Panama:
$\mu_m$ = `r para$PA$LMAm_mu_sun`,
$\mu_s$ = `r para$PA$LMAs_mu_sun`,
$\sigma_m$ = `r para$PA$LMAm_sig_sun`, and
$\alpha_m$ = `r para$PA$am`,
$\alpha_s$ = 0,
shade leaves in Panama:
$\mu_m$ = `r para$PA$LMAm_mu_shade`,
$\mu_s$ = `r para$PA$LMAs_mu_shade`,
$\sigma_m$ = `r para$PA$LMAm_sig_shade`,
$\alpha_m$ = `r para$PA$am`,
$\alpha_s$ = 0,
$\rho$ = `r para$PA$rho_shade`.

We finally calculated mass dependency (*b*) using the following ordinary least square regression:

$$
\mathrm{ln}(A_{\mathrm{area} \, i}) = \mathrm{ln}(c) + b \mathrm{ln}(\mathrm{LMA}_{i}).
$$

We repeated these steps 1000 times.

\newpage

# Figures

## `r s_fig("box_inter")`

![](`r here("figs/box_inter.png")`)

**`r s_fig("box_inter")`**:
Boxplots comparing leaf mass per area (LMA), photosynthetic leaf mass per area (LMAm; posterior medians), and structural leaf mass per area (LMAs; posterior medians) across
(a) deciduous (Dev) and evergreen (Eve) leaves and
(b) sites (wet and dry) and canopy strata (sun and shade) in Panama.
The results shown here include all leaves in the Panama dataset, whereas Figs. `r fig_num("box_de")`-`r fig_num("box_pa")` in the main text only include Panama species for which both sun and shade leaves were available.
The best model in the table 1 were used.
Boxplot symbols as in Figs. `r fig_num("box_de")`-`r fig_num("box_pa")`.
Groups sharing the same letters are not significantly different (P > 0.05; t-tests).

\newpage

## `r s_fig("box_frac_de")`

![](`r here("figs/box_frac_de.png")`)

**`r s_fig("box_frac_de")`**:
Boxplots comparing posterior medians of the latent variable *f* (the fraction of total LMA comprised by LMAm) across deciduous (Dev) and evergreen (Eve) leaves.
(i) GLOPNET dataset.
(ii) All leaves for Panama species.
(iii) Leaves for Panama species for which both sun and shade leaves were available.
Note that LMAm = *f* $\times$ LMA, and LMAs = (1 – *f*) $\times$ LMA.
The best model in the table 1 were used.
Boxplot symbols as in `r fig("box_de")`.
Groups sharing the same letters are not significantly different (P > 0.05; t-tests).

\newpage

## `r s_fig("box_frac_pa")`

![](`r here("figs/box_frac_pa.png")`)

**`r s_fig("box_frac_pa")`**:
Boxplots comparing posterior medians of the latent variable *f* (the fraction of total LMA comprised by LMAm) across sites (wet and dry) and canopy strata (sun and shade) in Panama.
The left panel shows leaves for Panama species for which both sun and shade leaves were available; and
the right panel shows all leaves for Panama.
Note that LMAm = *f* $\times$ LMA, and LMAs = (1 – *f*) $\times$ LMA.
The best model in the Table 1 were used.
Boxplot symbols as in `r fig("box_pa")`.
Groups sharing the same letters are not significantly different (P > 0.05; t-tests).

\newpage

## `r s_fig("mass_prop_sim")`

![](`r here("figs/mass_prop_sim.png")`){#fig-mass_prop_sim}

**`r s_fig("mass_prop_sim")`**:
The relationships between mass dependency (*b* in Equation 5 in the main text) and relative variance in LMAs to LMA for the different ranges of the scaling exponent $\alpha_m$ and $\alpha_s$.
(a) the scaling exponent $\alpha_m$ vary from 0.1 to 1.0 while the scaling exponent $\alpha_s$ is constant ($\alpha_s$ = `r para$GL$as`,).
(b) the scaling exponent $\alpha_s$ vary from -0.5 to 0.5 while the scaling exponent $\alpha_m$ is constant ($\alpha_m$ = `r para$GL$am`,).
Solid lines indicate simulated medians and shaded regions indicate 95% CI.
The photosynthetic rate (*A*~max~) is primarily mass-dependent (*b* > 0.5), primarily area-dependent (0.5 > *b* > 0) and purely area-dependent (*b* = 0) [@Osnas2018].
If *b* > 1, then *A*~max~ increases exponentially with LMA, which is not consistent with observed relationships [@Osnas2018].
Parameter settings:
$\alpha_0$ = `r para$GL$a0`,
$\mu_m$ = `r para$GL$LMAm_mu_gl`,
$\mu_s$ = `r para$GL$LMAs_mu_gl`,
$\sigma_m$ = `r para$GL$LMAm_sig_gl`.

\newpage


## `r s_fig("mass_prop_comp")`

![](`r here("figs/mass_prop_comp.png")`)

**`r s_fig("mass_prop_comp")`**:
The relationships between mass dependency (*b* in Equation 5 in the main text) and relative variance in LMAs to LMA for the simulated dataset generated by a normal distribution (N) and a multivariate normal distribution (MVN).
Parameter settings:
$\alpha_0$ = `r para$PA$a0`,
$\alpha_m$ = `r para$PA$am`,
$\alpha_s$ = 0,
$\mu_m$ = `r para$PA$LMAm_mu_shade`,
$\mu_s$ = `r para$PA$LMAs_mu_shade`,
$\sigma_m$ = `r para$PA$LMAm_sig_shade`, and
$\rho$ = `r para$PA$rho_shade`,

\newpage

## `r s_fig("gl_point_np2")`

![](`r here("figs/gl_point_np2.png")`)

**`r s_fig("gl_point_np2")`**:
Measured traits related to photosynthesis and metabolism (nitrogen and phosphorus per-unit leaf area; *N*~area~ and *P*~area~) are positively correlated with LMA and with estimates (posterior medians) of the metabolic and structural LMA components (LMAm and LMAs, respectively) in the GLOPNET dataset.
LMAm yields more consistent relationships compared to LMA and LMAs; e.g., evergreen and deciduous leaves align along a single relationship in panel b, but not in panels a or c.

\newpage

## `r s_fig("pa_point_npc_par")`

![](`r here("figs/pa_point_npc_par.png")`)

**`r s_fig("pa_point_npc_par")`**:
Partial regression plots for nitrogen, phosphorus and cellulose per-unit leaf area (*N*~area~, *P*~area~ and CL~area~).
(a) LMAs variation is controlled.
(b) LMAm variation is controlled.
The partial regression plots show separation between sun and shade when controlling for LMAs variation (i.e., LMAs does not explain the sun/shade difference), but overlapping distributions of sun and shade when controlling for LMAm variation (i.e., LMAm does explain the sun/shade difference).
Partial correlation coefficients ($\rho$) are shown.

\newpage

## `r s_fig("LMAm_LMAs")`

![](`r here("figs/ps_point.png")`)

**`r s_fig("LMAm_LMAs")`**
Pearson correlation coefficients for posterior medians of LMAm vs LMAs in the (a) GLOPNET and (b) Panama datasets.
The non-significant or weak *r* values indicate that a single axis could not accurately represent the two-dimensional space.
Symbols as in Main Text Figs. `r fig_num("gl_point")`-`r fig_num("pa_point")`.

\newpage

# Appendix S4: Stan code

## Stan code for the GLOPNET dataset

The best model for the GLOPNET dataset is LMAm-LMAs with the constraint of $\beta_m$ = 0.

```{stan, output.var="hoge",file=here('stan/ams_bs.stan'), eval=FALSE, echo=TRUE}
```

## Stan code for the Panama dataset

The best model for the Panama dataset is LMAm-LMAs-light with the constraint of $\alpha_s$ = 0 and $\beta_m$ = 0.

```{stan, output.var="hoge",file=here('stan/am_bs_opt.stan'), eval=FALSE, echo=TRUE}
```

# References
