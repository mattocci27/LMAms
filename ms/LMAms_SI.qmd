---
title: "Katabuchi et al., Decomposing leaf mass into metabolic and structural components explains divergent patterns of trait variation within and among plant species"
fontsize: 12pt
geometry: margin=1in
link-citations: yes
csl: templates/ecology.csl
bibliography: [LMA.bib]
crossref:
  eq-prefix: Eq.
format:
  html:
    theme: spacelab #readable #sandstone #spacelab #flatly
    toc: true
    toc-depth: 2
    toc-title: Contents
    self-contained: true
    smooth-scroll: true
    highlight-style: github
  docx:
    toc: true
    number-sections: false
    highlight-style: github
    html-math-method: katex
  pdf:
    toc: false
    keep-tex: true
    latex-clean: false
    pdf-engine: pdflatex
   # template: templates/eisvogel2.tex
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r caching, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
para <- yaml::yaml.load_file("../yml/para.yml")
```

\newpage

# Appendix S1: Prior information

The logarithms of *A*~area~, *R*~area~, and LL for leaf sample *i* were assumed to have a multivariate normal distribution as following:

\begin{align}
\left(
\begin{array}{ccc}
\mathrm{ln}(A_{\mathrm{area} \, i})\\
\mathrm{ln}(R_{\mathrm{area} \, i}) \\
\mathrm{ln}(\mathrm{LL}_i)
\end{array}
\right)
\sim \mathrm{MVN}
\left(
\begin{array}{rrr}
\mathrm{E}[A_{\mathrm{area} \, i}]\\
\mathrm{E}[R_{\mathrm{area} \, i}] &, \boldsymbol{\Sigma}\\
\mathrm{E}[\mathrm{LL}_i]
\end{array}
\right) \tag{S1}
\end{align}

where E[$\cdot$] indicates expected value; $\boldsymbol{\Sigma}$ indicates a covariance matrix.
Expected values are based on Eqs. 1-6 in the main text.

We used non-informative or weakly informative prior distributions [@Lemoine2019].
The covariance mkatrix in Eq. S1 was decomposed as ${\mathbf \Sigma} = {\mathrm diag}({\mathbf \sigma}){\mathbf \Omega}{\mathrm diag}({\mathbf \sigma}) = {\mathrm diag}({\mathbf \sigma}){\mathbf L}{\mathbf L}\prime {\mathrm diag}({\mathbf \sigma})$ using a Cholesky decomposition, where ${\mathbf \sigma}$ is a vector of $\sigma_{1}$, $\sigma_{2}$, and $\sigma_{3}$;  ${\mathbf \Omega}$ is a correlation matrix of $\rho_{12}$, $\rho_{13}$, and $\rho_{23}$; and **L** is a lower triangular matrix.
Instead of assigning prior distributions on directly, priors were assigned on and **L** to avoid a strong dependence between and [@Lewandowski2009; @Alvarez2014].
A prior for **L** was specified as a so-called LKJ distribution with shape parameter 2 [@Lewandowski2009], which is weakly informative for the correlation matrix.
A prior for ${\mathrm diag}({\mathbf \sigma})$ was specified as a Half-Cauchy distribution with location 0 and scale 5, which is weakly informative and allows for occasional large coefficients while still performing a reasonable amount of shrinkage for coefficients near zero [@Gelman2008].
A prior for $\mathbf{\sigma}$ was specified as a Half-Cauchy distribution with location 0 and scale 5, which is weakly informative and allows for occasional large coefficients while still performing a reasonable amount of shrinkage for coefficients near zero [@Gelman2008].
Priors for $\alpha_{0,p,s}$, $\beta_{0,p,s}$, and $\gamma_{0,p,s}$ in Eqs. 4-6 were weakly informative and specified as normal distributions with mean 0 and standard deviation 5.
Priors for *f~i~* in Eqs. 4-6 were non-informative and specified as uniform distributions with range (0, 1).


\newpage

# Appendix S2: Randomization (including Table AS1 and Figure AS1)

We generated 10 randomized datasets for each of the GLOPNET and the Panama datasets by shuffling each trait value across leaf samples, and fit the best models (Appendix S1) to the randomized data.

## Table AS1

- No_large_Rhat: The number of parameters (including transformed parameters) that shows Rhat (Gelman-Rubin statistic) greater than 1.05.
- No_divergence: The number of iterations that shows divergent transitions.

```{r randtab, echo=FALSE, eval=TRUE}
d <- read_csv("../data/rand.csv") |>
  dplyr::select(Data = data, Simulation_ID = sim_id, No_large_Rhat = rhat, No_divergence = div)

if ("html" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  # knitr::kable(d, format = "pipe", escape = FALSE) |>
  kable(d) |>
    #kable_styling()
    kable_classic(full_width = FALSE)
} else if ("docx" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  d |>
    kable(format = "pipe", escape = FALSE) |>
    kable_classic(full_width = FALSE)
} else if ("latex" == knitr::opts_knit$get("rmarkdown.pandoc.to")) {
  d |>
    kable(format = "pipe", escape = FALSE) |>
    kable_classic(full_width = FALSE)
}
```

Model results obtained from the randomized datasets did not convergent based on the Gelman-Rubin statistic or showed divergent transitions.

\newpage

## Figure AS1

Although many parameters showed large Rhat values, which suggests that the posterior distributions were not converged well, we checked the regression coefficients for GLOPNET ($\alpha_{0, p, s}$, $\beta_{0, s}$, and $\gamma_{0, p, s}$ in Eqs. 4-6 in the main text).
There are 10 independent simulations (randomizations) in total.
The scaling parameters in the randomized datasets did not show any patterns.
Thus, the tests with randomized data indicate that our model is not inherently prone to overfitting or to producing patterns from noise.
![
](../figs/coef_rand.png)


\newpage

# Appendix S3: Simulation for mass dependency of *A*~area~

To simulate mass dependency of *A*~area~, we generated LMAp and LMAs values for leaf sample *i* using normal distibutions (N) for GLPONET and sun leaves of Panama with a sample size of 100:

$$
\mathrm{ln}(\mathrm{LMAp}_{i}) \sim N(\mathrm{ln}(\mu_p), \sigma_p)
$$

$$
\mathrm{ln}(\mathrm{LMAs}_{i}) \sim N(\mathrm{ln}(\mu_s), \sigma_s)
$$

where
$\mu_p$ and $\mu_s$ are the mean of LMAp and LMAs on the log-scale, respectively, and
$\sigma_p$ and $\sigma_s$ are the standard deviation of LMAp and LMAs on the log-scale, respectively.

Because there was a weak negative correlation between LMAp and LMAs values of shade leaves in Panama, LMAp and LMAs values were generated using a multivairate normal distribution (MVN):

$$
\begin{bmatrix}
\mathrm{ln}(\mathrm{LMAp}_{i})\\
\mathrm{ln}(\mathrm{LMAs}_{i})
\end{bmatrix}
\sim \mathrm{MVN}
\left[
\begin{matrix}
\ln(\mu_{p})\\
\ln(\mu_{s})
\end{matrix}
,\mathbf{\Sigma}
\right]
$$

$$
\mathbf{\Sigma} = \
\begin{bmatrix}
\sigma_p^2 & \rho \sigma_p \sigma_s \\
\rho \sigma_p \sigma_s & \sigma_s^2 \\
\end{bmatrix}
$$

where $\Sigma$ is the covariance matrix of ln(LMAp) and ln(LMAs),
$\rho$ is the correlation coefficient between ln(LMAp) and ln(LMAs).

We used the empirical estimates for $\mu_p$, $\mu_s$, $\sigma_p$, and $\rho$ while with changing $\sigma_s$ between ln(1.01) and ln(10).
*A*~area~ was then generated based the values obtianed from the above simulation:

$$
\mathrm{ln}(A_{\mathrm{area} \, i}) = \mathrm{ln}(\alpha_0) + \alpha_p\mathrm{ln}(\mathrm{LMAp}_{i}) + \alpha_s\mathrm{ln}(\mathrm{LMAs}_{i}).
$$

Parameter settings are as following,
GLOPNET:
$\mu_p$ = `r para$GL$LMAp_mu_gl`,
$\mu_s$ = `r para$GL$LMAs_mu_gl`,
$\sigma_p$ = `r para$GL$LMAp_sig_gl`,
$\alpha_p$ = `r para$GL$ap`,
$\alpha_s$ = `r para$GL$as`,
sun leaves in Panama:
$\mu_p$ = `r para$PA$LMAp_mu_sun`,
$\mu_s$ = `r para$PA$LMAs_mu_sun`,
$\sigma_p$ = `r para$PA$LMAp_sig_sun`, and
$\alpha_p$ = `r para$PA$ap`,
$\alpha_s$ = 0,
shade leaves in Panama:
$\mu_p$ = `r para$PA$LMAp_mu_shade`,
$\mu_s$ = `r para$PA$LMAs_mu_shade`,
$\sigma_p$ = `r para$PA$LMAp_sig_shade`,
$\alpha_p$ = `r para$PA$ap`,
$\alpha_s$ = 0,
$\rho$ = -0.4.

We finally calculated mass dependicy (*b*) using the following ordinary least square regression:

$$
\mathrm{ln}(A_{\mathrm{area} \, i}) = \mathrm{ln}(a) + b \mathrm{ln}(\mathrm{LMA}_{i}).
$$

We repeated these steps 1000 times.

\newpage

# Figure S1

![
Pearson correlation coefficients for posterior medians of LMAp vs LMAs in the (a) GLOPNET and (b) Panama datasets.
The non-significant or weak *r* values indicate that a single axis could not accurately represent the two-dimensional space.
Symbols as in Main Text Figs. 1-2.
](../figs/ps_point.png){#fig-LMAp_LMAs}


\newpage

# Figure S2

![
Boxplots comparing leaf mass per area (LMA), photosynthetic leaf mass per area (LMAp; posterior means), and structural leaf mass per area (LMAs; posterior means) across sites (wet and dry) and canopy strata (sun and shade) in Panama.
The results shown here include all leaves in the Panama dataset, whereas Fig. 5 in the main text only includes Panama species for which both sun and shade leaves were available.
Boxplot symbols as in Fig. 5.
Groups sharing the same letters are not significantly different (P > 0.05; t-tests).
](../figs/box_inter.png){#fig-box_inter}

\newpage

# Figure S3

![
Boxplots comparing posterior medians of the latent variable f (the fraction of total LMA comprised by LMAm) across deciduous (D) and evergreen (E) leaves in GLOPNET and Panama, and across sites (wet and dry) and canopy strata (sun and shade) in Panama. Note that LMAm = f × LMA, and LMAs = (1 – f) × LMA.
(a) Deciduous and evergreen leaves in the GLOPNET dataset;
(b) deciduous and evergreen leaves for Panama species for which both sun and shade leaves were available;
(c) leaves for Panama species for which both sun and shade leaves were available; and
(d) all leaves for Panama. At the dry Panama site, the increase in LMA from shade to sun (Fig. 4) is due to roughly equal proportional increases in LMAm and LMAs (because f is similar between sun and shade), whereas at the wet Panama site, the increase in LMA from shade to sun (Fig. 4) is due primarily to increased LMAm (because f is greater in sun than shade).
GLOPNET results are for the Potential LL Model (Eq. 5), and Panama results are for the Optimal LL Model with site effects (Eq. 13 and Supporting Information, Section 3.1).
The center line in each box indicates the median, upper and lower box edges indicate the interquartile range, whiskers show 1.5 times the interquartile range, and points are outliers.
Groups sharing the same letters are not significantly different (P > 0.05; t-tests)."}

](../figs/box_frac.png){#fig-box_frac}

\newpage

# Figure S4

![
The relationships between mass dependency (*b* in Eq. 5 in the main text) and relative variance in LMAs to LMA for the different ranges of the scaling exponent $\alpha_p$ and $\alpha_s$.
**a**, the scaling exponent $\alpha_p$ vary from 0.1 to 1.0 while the scaling exponent $\alpha_s$ is constant ($\alpha_s$ = `r para$GL$as`,).
**b**, the scaling exponent $\alpha_s$ vary from -0.5 to 0.5 while the scaling exponent $\alpha_p$ is constant ($\alpha_p$ = `r para$GL$ap`,).
Solid lines indicate simulated means and shaded regions indicate 95% CI.
The photosynthetic rate (*A*~max~) is primarily mass-dependent (*b* > 0.5), primarily area-dependent (0.5 > *b* > 0) and purely area-dependent (*b* = 0) [@Osnas2018].
Note that when *b* > 1, *A*~area~ dramatically increase with LMA, which is not realistic.
Parameter settings:
$\alpha_0$ = `r para$GL$a0`,
$\mu_p$ = `r para$GL$LMAp_mu_gl`,
$\mu_s$ = `r para$GL$LMAs_mu_gl`,
$\sigma_p$ = `r para$GL$LMAp_sig_gl`.
](../figs/mass_prop_sim.png){#fig-mass_prop_sim}

\newpage

# Figure S5

![
The relationships between mass dependency (*b* in Eq. 5 in the main tex) and relative variance in LMAs to LMA for the simulated dataset gerenated by a normal distribution (N) and a multivariate normal distribution (MVN).
Parameter settings:
$\alpha_0$ = `r para$PA$a0`,
$\alpha_p$ = `r para$PA$ap`,
$\alpha_s$ = 0,
$\mu_p$ = `r para$PA$LMAp_mu_shade`,
$\mu_s$ = `r para$PA$LMAs_mu_shade`,
$\sigma_p$ = `r para$PA$LMAp_sig_shade`, and
$\rho$ = -0.4,
](../figs/mass_prop_comp.png){#fig-mass_prop_comp}

\newpage

# Figure S6

![
Measured traits related to photosynthesis and metabolism (nitrogen and phosphorus per-unit leaf area; *N*~area~ and *P*~area~) are positively correlated with LMA and with estimates (posterior means) of the photosynthetic and structural LMA components (LMAp and LMAs, respectively) in the GLOPNET dataset.
LMAp yields more consistent relationships compared to LMA and LMAs; e.g., evergreen and deciduous leaves align along a single relationship in panel b, but not in panels a or c.
](../figs/gl_point_np2.png){#fig-glnp}

# Appendix S4: Stan code

## Stan code for the GLOPNET dataset

The best model for the GLOPNET dataset is (2) LMAp and LMAs, and (b) $\beta_p = 0$.

```{stan, output.var="hoge",file="../stan/GL_Aps_LLs.stan", eval=FALSE, echo=TRUE}
```

## Stan code for the Panama dataset

The best model for the Panama dataset is (4) LMAp, LMAs and light, and (a) $\alpha_s = 0$  and $\beta_p = 0$,

```{stan, output.var="hoge",file="../stan/PA_Ap_LLs_opt.stan", eval=FALSE, echo=TRUE}
```

# References
